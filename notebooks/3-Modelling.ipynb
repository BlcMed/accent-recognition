{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../src\")\n",
    "from load_config import load_constants_from_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = load_constants_from_yaml(\"../constants.yml\")\n",
    "\n",
    "SAMPLING_RATING = constants[\"SAMPLING_RATING\"]\n",
    "FRAME_LENGTH_ENERGY = constants[\"FRAME_LENGTH_ENERGY\"]\n",
    "THRESHOLD_PERCENTAGE = constants[\"THRESHOLD_PERCENTAGE\"]\n",
    "MIN_SILENCE_DURATION = constants[\"MIN_SILENCE_DURATION\"]\n",
    "HOP_LENGTH = constants[\"HOP_LENGTH\"]\n",
    "TEST_SIZE = 0.2\n",
    "FIRST_LAYER_NEURONS = 128\n",
    "SECOND_LAYER_NEURONS = 64\n",
    "RANDOM_STATE = 42\n",
    "processed_data_path = \"../data/processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "VALIDATION_SPLIT = 0.2\n",
    "THRESHOLD_CLASSIFICATION = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(processed_data_path+\"df_transformed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>mfcc_4</th>\n",
       "      <th>mfcc_5</th>\n",
       "      <th>mfcc_6</th>\n",
       "      <th>mfcc_7</th>\n",
       "      <th>mfcc_8</th>\n",
       "      <th>mfcc_9</th>\n",
       "      <th>mfcc_10</th>\n",
       "      <th>mfcc_11</th>\n",
       "      <th>mfcc_12</th>\n",
       "      <th>mfcc_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.199065</td>\n",
       "      <td>-0.881256</td>\n",
       "      <td>0.591127</td>\n",
       "      <td>-0.169963</td>\n",
       "      <td>0.582260</td>\n",
       "      <td>0.748747</td>\n",
       "      <td>1.134152</td>\n",
       "      <td>0.801761</td>\n",
       "      <td>0.953608</td>\n",
       "      <td>0.726335</td>\n",
       "      <td>0.872313</td>\n",
       "      <td>0.664804</td>\n",
       "      <td>0.865082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.268200</td>\n",
       "      <td>-1.028002</td>\n",
       "      <td>0.353531</td>\n",
       "      <td>-0.367497</td>\n",
       "      <td>0.426105</td>\n",
       "      <td>0.683014</td>\n",
       "      <td>1.162779</td>\n",
       "      <td>0.914434</td>\n",
       "      <td>1.118985</td>\n",
       "      <td>0.903471</td>\n",
       "      <td>1.027281</td>\n",
       "      <td>0.782093</td>\n",
       "      <td>0.921110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.359687</td>\n",
       "      <td>-1.228744</td>\n",
       "      <td>-0.007906</td>\n",
       "      <td>-0.736143</td>\n",
       "      <td>0.002961</td>\n",
       "      <td>0.278296</td>\n",
       "      <td>0.772721</td>\n",
       "      <td>0.561240</td>\n",
       "      <td>0.813884</td>\n",
       "      <td>0.648693</td>\n",
       "      <td>0.813558</td>\n",
       "      <td>0.586497</td>\n",
       "      <td>0.760301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.359693</td>\n",
       "      <td>-1.228758</td>\n",
       "      <td>-0.007932</td>\n",
       "      <td>-0.736172</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.278254</td>\n",
       "      <td>0.772673</td>\n",
       "      <td>0.561186</td>\n",
       "      <td>0.813826</td>\n",
       "      <td>0.648631</td>\n",
       "      <td>0.813491</td>\n",
       "      <td>0.586419</td>\n",
       "      <td>0.760223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-2.359697</td>\n",
       "      <td>-1.228765</td>\n",
       "      <td>-0.007944</td>\n",
       "      <td>-0.736186</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>0.278235</td>\n",
       "      <td>0.772650</td>\n",
       "      <td>0.561161</td>\n",
       "      <td>0.813798</td>\n",
       "      <td>0.648601</td>\n",
       "      <td>0.813459</td>\n",
       "      <td>0.586382</td>\n",
       "      <td>0.760185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label    mfcc_1    mfcc_2    mfcc_3    mfcc_4    mfcc_5    mfcc_6  \\\n",
       "0      1 -2.199065 -0.881256  0.591127 -0.169963  0.582260  0.748747   \n",
       "1      1 -2.268200 -1.028002  0.353531 -0.367497  0.426105  0.683014   \n",
       "2      1 -2.359687 -1.228744 -0.007906 -0.736143  0.002961  0.278296   \n",
       "3      1 -2.359693 -1.228758 -0.007932 -0.736172  0.002924  0.278254   \n",
       "4      1 -2.359697 -1.228765 -0.007944 -0.736186  0.002906  0.278235   \n",
       "\n",
       "     mfcc_7    mfcc_8    mfcc_9   mfcc_10   mfcc_11   mfcc_12   mfcc_13  \n",
       "0  1.134152  0.801761  0.953608  0.726335  0.872313  0.664804  0.865082  \n",
       "1  1.162779  0.914434  1.118985  0.903471  1.027281  0.782093  0.921110  \n",
       "2  0.772721  0.561240  0.813884  0.648693  0.813558  0.586497  0.760301  \n",
       "3  0.772673  0.561186  0.813826  0.648631  0.813491  0.586419  0.760223  \n",
       "4  0.772650  0.561161  0.813798  0.648601  0.813459  0.586382  0.760185  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\"label\", axis=1)\n",
    "y = df[\"label\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=TEST_SIZE, stratify=y, random_state=RANDOM_STATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSVDataset(Dataset):\n",
    "    def __init__(self, X_data, y_data):\n",
    "        self.X_data = X_data\n",
    "        self.y_data = y_data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset instances for training and testing\n",
    "train_dataset = CSVDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = CSVDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoader to batch and shuffle the data\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_shape, first_layer_neurons, second_layer_neurons):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_shape, first_layer_neurons)\n",
    "        self.fc2 = nn.Linear(first_layer_neurons, second_layer_neurons)\n",
    "        self.output = nn.Linear(second_layer_neurons, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]\n",
    "net = Net(\n",
    "    input_shape,\n",
    "    first_layer_neurons=FIRST_LAYER_NEURONS,\n",
    "    second_layer_neurons=SECOND_LAYER_NEURONS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4696\n",
      "Epoch 2, Loss: 0.4184\n",
      "Epoch 3, Loss: 0.3958\n",
      "Epoch 4, Loss: 0.3802\n",
      "Epoch 5, Loss: 0.3694\n",
      "Epoch 6, Loss: 0.3614\n",
      "Epoch 7, Loss: 0.3549\n",
      "Epoch 8, Loss: 0.3493\n",
      "Epoch 9, Loss: 0.3450\n",
      "Epoch 10, Loss: 0.3416\n",
      "Epoch 11, Loss: 0.3380\n",
      "Epoch 12, Loss: 0.3349\n",
      "Epoch 13, Loss: 0.3324\n",
      "Epoch 14, Loss: 0.3306\n",
      "Epoch 15, Loss: 0.3281\n",
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        labels.unsqueeze_(-1)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "print(\"Training finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            labels.unsqueeze_(-1)\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # apply a threshold to outputs\n",
    "            predicted = (outputs > THRESHOLD_CLASSIFICATION).float()\n",
    "\n",
    "            # Collect predictions and labels for metrics\n",
    "            all_predictions.extend(predicted.cpu().numpy().flatten())\n",
    "            all_labels.extend(labels.cpu().numpy().flatten())\n",
    "\n",
    "            # correct predictions count\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = correct / total * 100  # percentage\n",
    "\n",
    "    # Calculate precision, recall, F1 score\n",
    "    precision = precision_score(all_labels, all_predictions)\n",
    "    recall = recall_score(all_labels, all_predictions)\n",
    "    f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_labels, all_predictions, normalize=\"all\")\n",
    "\n",
    "    return {\n",
    "        \"avg_loss\": avg_loss,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"confusion_matrix\": conf_matrix,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(results):\n",
    "    print(f\"Average Loss: {results['avg_loss']:.4f}\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.2f}%\")\n",
    "    print(f\"Precision: {results['precision']:.4f}\")\n",
    "    print(f\"Recall: {results['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {results['f1_score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{results['confusion_matrix']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.3212\n",
      "Accuracy: 85.77%\n",
      "Precision: 0.8225\n",
      "Recall: 0.8127\n",
      "F1 Score: 0.8176\n",
      "Confusion Matrix:\n",
      "[[0.53884806 0.06881211]\n",
      " [0.07349657 0.31884326]]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(net, train_loader, criterion)\n",
    "show_results(results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model on the testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss: 0.3405\n",
      "Accuracy: 84.83%\n",
      "Precision: 0.8105\n",
      "Recall: 0.8004\n",
      "F1 Score: 0.8054\n",
      "Confusion Matrix:\n",
      "[[0.53424146 0.07342094]\n",
      " [0.07831449 0.31402312]]\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_model(net, test_loader, criterion)\n",
    "show_results(results=results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"../models/net_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
